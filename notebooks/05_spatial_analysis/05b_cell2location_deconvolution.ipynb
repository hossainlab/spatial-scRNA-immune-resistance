{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Deconvolution with Cell2Location\n",
    "\n",
    "## Overview\n",
    "This notebook uses cell2location to deconvolve spatial transcriptomics spots into cell type compositions using our scRNA-seq reference atlas.\n",
    "\n",
    "### Objectives\n",
    "1. Prepare scRNA-seq reference signatures\n",
    "2. Train cell2location model on spatial data\n",
    "3. Map cell types to spatial coordinates\n",
    "4. Identify spatial niches\n",
    "\n",
    "### Why Cell2Location?\n",
    "- Bayesian model accounting for technical noise\n",
    "- Estimates absolute cell abundances\n",
    "- GPU-accelerated for scalability\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import anndata as ad\n",
    "import cell2location\n",
    "from cell2location.utils.filtering import filter_genes\n",
    "from cell2location.models import RegressionModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "DATA_PROCESSED_SCRNA = PROJECT_ROOT / 'data' / 'processed' / 'scrna'\n",
    "DATA_RAW_SPATIAL = PROJECT_ROOT / 'data' / 'raw' / 'spatial'\n",
    "DATA_PROCESSED_SPATIAL = PROJECT_ROOT / 'data' / 'processed' / 'spatial'\n",
    "MODELS = PROJECT_ROOT / 'results' / 'models'\n",
    "FIGURES = PROJECT_ROOT / 'results' / 'figures'\n",
    "CONFIG_PATH = PROJECT_ROOT / 'config' / 'analysis_params.yaml'\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Reference scRNA-seq Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotated scRNA-seq reference\n",
    "adata_ref = sc.read_h5ad(DATA_PROCESSED_SCRNA / 'integrated_atlas_annotated.h5ad')\n",
    "\n",
    "print(f\"Reference atlas:\")\n",
    "print(f\"  Cells: {adata_ref.n_obs}\")\n",
    "print(f\"  Genes: {adata_ref.n_vars}\")\n",
    "print(f\"\\nCell types: {adata_ref.obs['cell_type_major'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use raw counts for reference\n",
    "if 'counts' in adata_ref.layers:\n",
    "    adata_ref.X = adata_ref.layers['counts'].copy()\n",
    "\n",
    "# Filter genes for cell2location\n",
    "selected_genes = filter_genes(\n",
    "    adata_ref,\n",
    "    cell_count_cutoff=5,\n",
    "    cell_percentage_cutoff2=0.03,\n",
    "    nonz_mean_cutoff=1.12\n",
    ")\n",
    "\n",
    "adata_ref = adata_ref[:, selected_genes].copy()\n",
    "print(f\"Selected genes for reference: {adata_ref.n_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Reference Model\n",
    "\n",
    "Estimate reference cell type signatures using negative binomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup reference model\n",
    "cell2location.models.RegressionModel.setup_anndata(\n",
    "    adata_ref,\n",
    "    batch_key='dataset',\n",
    "    labels_key='cell_type_major'\n",
    ")\n",
    "\n",
    "# Create model\n",
    "mod_ref = RegressionModel(adata_ref)\n",
    "\n",
    "print(\"Reference model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train reference model\n",
    "mod_ref.train(\n",
    "    max_epochs=250,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    batch_size=2500\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "mod_ref.plot_history(20)\n",
    "plt.savefig(FIGURES / 'cell2location_ref_training.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export reference signatures\n",
    "adata_ref = mod_ref.export_posterior(\n",
    "    adata_ref,\n",
    "    sample_kwargs={'num_samples': 1000, 'batch_size': 2500, 'use_gpu': True}\n",
    ")\n",
    "\n",
    "# Extract signature matrix\n",
    "inf_aver = adata_ref.varm['means_per_cluster_mu_fg'].copy()\n",
    "print(f\"Reference signatures shape: {inf_aver.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Spatial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spatial data (example for GSE203612)\n",
    "spatial_id = \"GSE203612\"\n",
    "sample_name = \"sample1\"  # Modify based on your data\n",
    "\n",
    "spatial_path = DATA_RAW_SPATIAL / spatial_id / sample_name\n",
    "\n",
    "if spatial_path.exists():\n",
    "    adata_st = sc.read_visium(spatial_path, count_file='filtered_feature_bc_matrix.h5')\n",
    "    adata_st.var_names_make_unique()\n",
    "    \n",
    "    print(f\"Loaded spatial data:\")\n",
    "    print(f\"  Spots: {adata_st.n_obs}\")\n",
    "    print(f\"  Genes: {adata_st.n_vars}\")\n",
    "else:\n",
    "    print(f\"Spatial data not found at: {spatial_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersect genes\n",
    "shared_genes = [g for g in adata_ref.var_names if g in adata_st.var_names]\n",
    "adata_st = adata_st[:, shared_genes].copy()\n",
    "print(f\"Shared genes: {len(shared_genes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Cell2Location Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup spatial model\n",
    "cell2location.models.Cell2location.setup_anndata(\n",
    "    adata_st,\n",
    "    batch_key=None\n",
    ")\n",
    "\n",
    "# Create model with reference signatures\n",
    "c2l_params = config['spatial']['cell2location']\n",
    "\n",
    "mod_st = cell2location.models.Cell2location(\n",
    "    adata_st,\n",
    "    cell_state_df=inf_aver,\n",
    "    N_cells_per_location=c2l_params['n_cells_per_location'],\n",
    "    detection_alpha=c2l_params['detection_alpha']\n",
    ")\n",
    "\n",
    "print(\"Spatial model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train spatial model\n",
    "mod_st.train(\n",
    "    max_epochs=c2l_params['max_epochs'],\n",
    "    batch_size=None,\n",
    "    train_size=1,\n",
    "    use_gpu=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "mod_st.plot_history(1000)\n",
    "plt.savefig(FIGURES / f'{spatial_id}_{sample_name}_c2l_training.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export posterior\n",
    "adata_st = mod_st.export_posterior(\n",
    "    adata_st,\n",
    "    sample_kwargs={'num_samples': 1000, 'batch_size': mod_st.adata.n_obs, 'use_gpu': True}\n",
    ")\n",
    "\n",
    "# Cell type abundances are in adata_st.obsm['q05_cell_abundance_w_sf']\n",
    "print(\"Deconvolution complete!\")\n",
    "print(f\"Cell abundances shape: {adata_st.obsm['q05_cell_abundance_w_sf'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Spatial Cell Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cell type abundances to obs for plotting\n",
    "cell_types = list(inf_aver.columns)\n",
    "abundance_df = pd.DataFrame(\n",
    "    adata_st.obsm['q05_cell_abundance_w_sf'],\n",
    "    index=adata_st.obs_names,\n",
    "    columns=cell_types\n",
    ")\n",
    "\n",
    "for ct in cell_types:\n",
    "    adata_st.obs[f'abundance_{ct}'] = abundance_df[ct].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial distribution of cell types\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ct in enumerate(cell_types[:8]):\n",
    "    sq.pl.spatial_scatter(\n",
    "        adata_st,\n",
    "        color=f'abundance_{ct}',\n",
    "        ax=axes[i],\n",
    "        title=ct,\n",
    "        cmap='viridis',\n",
    "        size=1.5\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES / f'{spatial_id}_{sample_name}_cell_abundances.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identify Spatial Niches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster spots by cell type composition\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_niches = config['spatial']['niche']['n_neighborhoods']\n",
    "\n",
    "# Cluster based on cell abundances\n",
    "kmeans = KMeans(n_clusters=n_niches, random_state=config['random_seed'])\n",
    "adata_st.obs['spatial_niche'] = kmeans.fit_predict(abundance_df.values).astype(str)\n",
    "\n",
    "print(f\"Identified {n_niches} spatial niches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize niches\n",
    "sq.pl.spatial_scatter(\n",
    "    adata_st,\n",
    "    color='spatial_niche',\n",
    "    size=1.5,\n",
    "    save=f'{spatial_id}_{sample_name}_niches.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterize niches by cell type composition\n",
    "niche_composition = abundance_df.groupby(adata_st.obs['spatial_niche']).mean()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(niche_composition.T, cmap='YlOrRd', annot=True, fmt='.1f')\n",
    "plt.title('Cell Type Composition per Spatial Niche')\n",
    "plt.xlabel('Niche')\n",
    "plt.ylabel('Cell Type')\n",
    "plt.savefig(FIGURES / f'{spatial_id}_{sample_name}_niche_composition.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save deconvolved spatial data\n",
    "output_path = DATA_PROCESSED_SPATIAL / f'{spatial_id}_{sample_name}_deconvolved.h5ad'\n",
    "adata_st.write(output_path)\n",
    "print(f\"Saved deconvolved data to: {output_path}\")\n",
    "\n",
    "# Save model\n",
    "model_path = MODELS / f'cell2location_{spatial_id}_{sample_name}'\n",
    "mod_st.save(str(model_path), overwrite=True)\n",
    "print(f\"Saved model to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Completed\n",
    "- Trained reference signatures from scRNA-seq\n",
    "- Deconvolved spatial spots to cell types\n",
    "- Identified spatial niches\n",
    "\n",
    "### Next Steps\n",
    "1. Spatial statistics in `05d_spatial_statistics.ipynb`\n",
    "2. Correlate niches with resistance in `06_resistance_analysis/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
