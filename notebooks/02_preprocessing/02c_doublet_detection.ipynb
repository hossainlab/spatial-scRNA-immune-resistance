{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doublet Detection and Removal\n",
    "\n",
    "## Overview\n",
    "This notebook identifies and removes doublets (droplets containing two or more cells) from scRNA-seq data.\n",
    "\n",
    "### Why Remove Doublets?\n",
    "- Doublets appear as intermediate cell types or rare populations\n",
    "- They can confound clustering and differential expression\n",
    "- Expected doublet rate: ~0.8% per 1000 cells loaded\n",
    "\n",
    "### Methods\n",
    "- **Scrublet**: Simulates doublets and scores cells based on similarity\n",
    "- **DoubletDetection**: Alternative method using boosted classifiers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import warnings\n",
    "\n",
    "# Doublet detection\n",
    "import scrublet as scr\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "DATA_PROCESSED = PROJECT_ROOT / 'data' / 'processed' / 'scrna'\n",
    "FIGURES = PROJECT_ROOT / 'results' / 'figures'\n",
    "CONFIG_PATH = PROJECT_ROOT / 'config' / 'analysis_params.yaml'\n",
    "\n",
    "# Load configuration\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "SEED = config['random_seed']\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "geo_id = \"GSE115978\"\n",
    "input_path = DATA_PROCESSED / f'{geo_id}_processed.h5ad'\n",
    "\n",
    "if input_path.exists():\n",
    "    adata = sc.read_h5ad(input_path)\n",
    "    print(f\"Loaded: {input_path}\")\n",
    "    print(f\"Cells: {adata.n_obs}\")\n",
    "    print(f\"Genes: {adata.n_vars}\")\n",
    "else:\n",
    "    print(f\"File not found: {input_path}\")\n",
    "    print(\"Please run 02b_normalization_hvg.ipynb first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Scrublet\n",
    "\n",
    "Scrublet simulates artificial doublets by averaging pairs of cells, then scores each cell based on its similarity to simulated doublets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scrublet(adata, expected_doublet_rate=0.08):\n",
    "    \"\"\"\n",
    "    Run Scrublet doublet detection.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : AnnData\n",
    "        Annotated data matrix (use raw counts)\n",
    "    expected_doublet_rate : float\n",
    "        Expected fraction of doublets\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    AnnData\n",
    "        Data with doublet scores and predictions\n",
    "    \"\"\"\n",
    "    # Use raw counts for Scrublet\n",
    "    if 'counts' in adata.layers:\n",
    "        counts = adata.layers['counts']\n",
    "    else:\n",
    "        counts = adata.X\n",
    "    \n",
    "    # Initialize Scrublet\n",
    "    scrub = scr.Scrublet(\n",
    "        counts,\n",
    "        expected_doublet_rate=expected_doublet_rate,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    \n",
    "    # Run detection\n",
    "    doublet_scores, predicted_doublets = scrub.scrub_doublets(\n",
    "        min_counts=2,\n",
    "        min_cells=3,\n",
    "        min_gene_variability_pctl=85,\n",
    "        n_prin_comps=30\n",
    "    )\n",
    "    \n",
    "    # Add to adata\n",
    "    adata.obs['doublet_score'] = doublet_scores\n",
    "    adata.obs['predicted_doublet'] = predicted_doublets\n",
    "    \n",
    "    # Store scrublet object for visualization\n",
    "    return adata, scrub\n",
    "\n",
    "print(\"Scrublet function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Scrublet\n",
    "expected_rate = config['qc']['doublet_rate']\n",
    "print(f\"Expected doublet rate: {expected_rate}\")\n",
    "\n",
    "adata, scrub = run_scrublet(adata, expected_doublet_rate=expected_rate)\n",
    "\n",
    "# Summary\n",
    "n_doublets = adata.obs['predicted_doublet'].sum()\n",
    "pct_doublets = 100 * n_doublets / adata.n_obs\n",
    "\n",
    "print(f\"\\nDoublet detection results:\")\n",
    "print(f\"  Predicted doublets: {n_doublets} ({pct_doublets:.2f}%)\")\n",
    "print(f\"  Threshold: {scrub.threshold_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Doublet Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of doublet scores\n",
    "scrub.plot_histogram()\n",
    "plt.savefig(FIGURES / f'{geo_id}_doublet_histogram.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP colored by doublet score\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=['doublet_score', 'predicted_doublet'],\n",
    "    ncols=2,\n",
    "    save=f'_{geo_id}_doublets.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublets per cluster\n",
    "default_res = config['clustering']['default_resolution']\n",
    "cluster_key = f'leiden_{default_res}'\n",
    "\n",
    "if cluster_key in adata.obs.columns:\n",
    "    doublet_by_cluster = adata.obs.groupby(cluster_key)['predicted_doublet'].agg(['sum', 'count'])\n",
    "    doublet_by_cluster['pct'] = 100 * doublet_by_cluster['sum'] / doublet_by_cluster['count']\n",
    "    \n",
    "    print(\"Doublet percentage by cluster:\")\n",
    "    print(doublet_by_cluster.sort_values('pct', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Remove Doublets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out doublets\n",
    "n_before = adata.n_obs\n",
    "\n",
    "adata_singlets = adata[~adata.obs['predicted_doublet']].copy()\n",
    "\n",
    "n_after = adata_singlets.n_obs\n",
    "n_removed = n_before - n_after\n",
    "\n",
    "print(f\"Removed {n_removed} doublets ({100*n_removed/n_before:.2f}%)\")\n",
    "print(f\"Cells remaining: {n_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute UMAP after doublet removal\n",
    "sc.pp.neighbors(adata_singlets, n_pcs=config['dim_reduction']['n_pcs'], random_state=SEED)\n",
    "sc.tl.umap(adata_singlets, random_state=SEED)\n",
    "\n",
    "# Visualize\n",
    "sc.pl.umap(\n",
    "    adata_singlets,\n",
    "    color=[cluster_key],\n",
    "    title='After doublet removal',\n",
    "    save=f'_{geo_id}_after_doublet_removal.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Final Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data with doublets removed\n",
    "output_path = DATA_PROCESSED / f'{geo_id}_final.h5ad'\n",
    "adata_singlets.write(output_path)\n",
    "\n",
    "print(f\"Saved final preprocessed data to: {output_path}\")\n",
    "print(f\"\\nFinal data summary:\")\n",
    "print(f\"  Cells: {adata_singlets.n_obs}\")\n",
    "print(f\"  Genes: {adata_singlets.n_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Preprocessing Complete\n",
    "This concludes the preprocessing phase for this dataset.\n",
    "\n",
    "### Data Status\n",
    "- Quality control: Complete\n",
    "- Normalization: Complete\n",
    "- HVG selection: Complete\n",
    "- Dimensionality reduction: Complete\n",
    "- Doublet removal: Complete\n",
    "\n",
    "### Next Steps\n",
    "1. Repeat preprocessing for all datasets\n",
    "2. Proceed to `03_integration/` for batch correction across datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
