{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Transcriptomics Data Download\n",
    "\n",
    "## Overview\n",
    "This notebook downloads spatial transcriptomics datasets for integration with scRNA-seq data in the immunotherapy resistance atlas.\n",
    "\n",
    "### Datasets\n",
    "| GEO ID | Cancer Type | Platform | Notes |\n",
    "|--------|-------------|----------|-------|\n",
    "| GSE203612 | Gastric Cancer | 10x Visium | Primary tumors |\n",
    "| Additional | NSCLC | CosMx | To be added |\n",
    "| Additional | Breast | 10x Visium | To be added |\n",
    "\n",
    "### Spatial Platforms\n",
    "- **10x Visium**: Spot-based, ~5000 spots per section, ~1-10 cells per spot\n",
    "- **CosMx**: Single-cell resolution, up to 1000 genes\n",
    "- **MERFISH**: Single-cell resolution, up to 500 genes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "DATA_RAW = PROJECT_ROOT / 'data' / 'raw' / 'spatial'\n",
    "CONFIG_PATH = PROJECT_ROOT / 'config' / 'analysis_params.yaml'\n",
    "\n",
    "print(f\"Data will be saved to: {DATA_RAW}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Get spatial dataset list\n",
    "spatial_datasets = config['datasets']['spatial']\n",
    "\n",
    "print(f\"Spatial datasets to download: {len(spatial_datasets)}\")\n",
    "for ds in spatial_datasets:\n",
    "    print(f\"  - {ds['id']}: {ds['cancer_type']} ({ds['platform']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spatial Data Formats\n",
    "\n",
    "### 10x Visium Output Structure\n",
    "```\n",
    "sample/\n",
    "├── filtered_feature_bc_matrix.h5\n",
    "├── spatial/\n",
    "│   ├── tissue_hires_image.png\n",
    "│   ├── tissue_lowres_image.png\n",
    "│   ├── scalefactors_json.json\n",
    "│   └── tissue_positions_list.csv\n",
    "└── analysis/\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "### Key Files\n",
    "- **filtered_feature_bc_matrix.h5**: Gene expression matrix\n",
    "- **tissue_positions_list.csv**: Spot coordinates\n",
    "- **tissue_hires_image.png**: H&E stained tissue image\n",
    "- **scalefactors_json.json**: Scaling factors for coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, output_path, chunk_size=8192):\n",
    "    \"\"\"\n",
    "    Download file with progress bar.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(output_path, 'wb') as f:\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=output_path.name) as pbar:\n",
    "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                f.write(chunk)\n",
    "                pbar.update(len(chunk))\n",
    "\n",
    "\n",
    "def load_visium_data(sample_dir):\n",
    "    \"\"\"\n",
    "    Load 10x Visium spatial data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_dir : Path\n",
    "        Directory containing Visium output\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    AnnData\n",
    "        Spatial AnnData object with coordinates and images\n",
    "    \"\"\"\n",
    "    sample_dir = Path(sample_dir)\n",
    "    \n",
    "    # Read spatial data using scanpy\n",
    "    adata = sc.read_visium(\n",
    "        sample_dir,\n",
    "        count_file='filtered_feature_bc_matrix.h5',\n",
    "        load_images=True\n",
    "    )\n",
    "    \n",
    "    # Ensure gene names are unique\n",
    "    adata.var_names_make_unique()\n",
    "    \n",
    "    return adata\n",
    "\n",
    "print(\"Spatial data loading functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Spatial Datasets\n",
    "\n",
    "### 3.1 GSE203612 - Gastric Cancer Visium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GSE203612 - Gastric cancer spatial transcriptomics\n",
    "geo_id = \"GSE203612\"\n",
    "output_dir = DATA_RAW / geo_id\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Downloading {geo_id}...\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"\\nGEO URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={geo_id}\")\n",
    "print(\"\\nNote: Download supplementary files manually from GEO.\")\n",
    "print(\"\\nExpected files:\")\n",
    "print(\"  - Space Ranger output for each sample\")\n",
    "print(\"  - Tissue images\")\n",
    "print(\"  - Metadata with clinical information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Manual Download Instructions for Spatial Data\n",
    "\n",
    "Spatial transcriptomics data often includes large image files and requires careful organization:\n",
    "\n",
    "1. Go to the GEO page\n",
    "2. Download supplementary files (often as .tar.gz archives)\n",
    "3. Extract and organize as:\n",
    "\n",
    "```\n",
    "data/raw/spatial/GSEXXX/\n",
    "├── sample1/\n",
    "│   ├── filtered_feature_bc_matrix.h5\n",
    "│   └── spatial/\n",
    "├── sample2/\n",
    "│   ├── filtered_feature_bc_matrix.h5\n",
    "│   └── spatial/\n",
    "└── metadata.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for existing spatial data\n",
    "print(\"Checking for existing spatial data:\\n\")\n",
    "\n",
    "for dataset in spatial_datasets:\n",
    "    geo_id = dataset['id']\n",
    "    data_dir = DATA_RAW / geo_id\n",
    "    \n",
    "    if data_dir.exists():\n",
    "        # Count potential samples\n",
    "        samples = [d for d in data_dir.iterdir() if d.is_dir()]\n",
    "        h5_files = list(data_dir.rglob('*.h5'))\n",
    "        \n",
    "        print(f\"{geo_id}:\")\n",
    "        print(f\"  - Directory exists: Yes\")\n",
    "        print(f\"  - Subdirectories: {len(samples)}\")\n",
    "        print(f\"  - H5 files: {len(h5_files)}\")\n",
    "    else:\n",
    "        print(f\"{geo_id}: NOT DOWNLOADED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Spatial Data Structure\n",
    "\n",
    "After downloading, verify that spatial data has the correct structure for loading with scanpy/squidpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_visium_structure(sample_dir):\n",
    "    \"\"\"\n",
    "    Verify that a directory contains valid Visium data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_dir : Path\n",
    "        Directory to check\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Status of each required file\n",
    "    \"\"\"\n",
    "    sample_dir = Path(sample_dir)\n",
    "    \n",
    "    required_files = {\n",
    "        'count_matrix': sample_dir / 'filtered_feature_bc_matrix.h5',\n",
    "        'positions': sample_dir / 'spatial' / 'tissue_positions_list.csv',\n",
    "        'scalefactors': sample_dir / 'spatial' / 'scalefactors_json.json',\n",
    "        'hires_image': sample_dir / 'spatial' / 'tissue_hires_image.png',\n",
    "        'lowres_image': sample_dir / 'spatial' / 'tissue_lowres_image.png',\n",
    "    }\n",
    "    \n",
    "    status = {}\n",
    "    for name, path in required_files.items():\n",
    "        status[name] = path.exists()\n",
    "    \n",
    "    return status\n",
    "\n",
    "\n",
    "# Verify downloaded spatial data\n",
    "print(\"Verifying spatial data structure:\\n\")\n",
    "\n",
    "for dataset in spatial_datasets:\n",
    "    geo_id = dataset['id']\n",
    "    data_dir = DATA_RAW / geo_id\n",
    "    \n",
    "    if data_dir.exists():\n",
    "        # Check each subdirectory as a potential sample\n",
    "        for sample_dir in [d for d in data_dir.iterdir() if d.is_dir()]:\n",
    "            status = verify_visium_structure(sample_dir)\n",
    "            \n",
    "            all_present = all(status.values())\n",
    "            status_str = \"VALID\" if all_present else \"INCOMPLETE\"\n",
    "            \n",
    "            print(f\"{geo_id}/{sample_dir.name}: {status_str}\")\n",
    "            \n",
    "            if not all_present:\n",
    "                for name, present in status.items():\n",
    "                    if not present:\n",
    "                        print(f\"    Missing: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Loading Spatial Data\n",
    "\n",
    "Let's test loading a spatial dataset to ensure it's properly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test loading a sample\n",
    "# Uncomment and modify path once data is downloaded\n",
    "\n",
    "# sample_path = DATA_RAW / 'GSE203612' / 'sample1'\n",
    "# \n",
    "# if sample_path.exists():\n",
    "#     adata = load_visium_data(sample_path)\n",
    "#     \n",
    "#     print(f\"Loaded spatial data:\")\n",
    "#     print(f\"  - Spots: {adata.n_obs}\")\n",
    "#     print(f\"  - Genes: {adata.n_vars}\")\n",
    "#     print(f\"  - Spatial coordinates: {adata.obsm['spatial'].shape}\")\n",
    "#     print(f\"  - Images loaded: {list(adata.uns['spatial'].keys())}\")\n",
    "# else:\n",
    "#     print(f\"Sample not found at: {sample_path}\")\n",
    "\n",
    "print(\"Test loading code ready - uncomment once data is downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Spatial Dataset Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata for spatial datasets\n",
    "spatial_metadata = []\n",
    "\n",
    "for dataset in spatial_datasets:\n",
    "    geo_id = dataset['id']\n",
    "    data_dir = DATA_RAW / geo_id\n",
    "    \n",
    "    # Count samples if directory exists\n",
    "    n_samples = 0\n",
    "    if data_dir.exists():\n",
    "        n_samples = len([d for d in data_dir.iterdir() if d.is_dir()])\n",
    "    \n",
    "    record = {\n",
    "        'geo_id': geo_id,\n",
    "        'cancer_type': dataset['cancer_type'],\n",
    "        'platform': dataset['platform'],\n",
    "        'data_path': str(data_dir),\n",
    "        'downloaded': data_dir.exists() and n_samples > 0,\n",
    "        'n_samples': n_samples\n",
    "    }\n",
    "    \n",
    "    spatial_metadata.append(record)\n",
    "\n",
    "# Create DataFrame\n",
    "spatial_df = pd.DataFrame(spatial_metadata)\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = DATA_RAW / 'spatial_dataset_metadata.csv'\n",
    "spatial_df.to_csv(metadata_path, index=False)\n",
    "\n",
    "print(f\"Metadata saved to: {metadata_path}\")\n",
    "display(spatial_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Additional Spatial Data Resources\n",
    "\n",
    "### Public Spatial Transcriptomics Repositories\n",
    "\n",
    "1. **10x Genomics Datasets**: https://www.10xgenomics.com/resources/datasets\n",
    "   - Curated Visium datasets with full Space Ranger output\n",
    "   \n",
    "2. **SpatialDB**: http://www.spatialomics.org/\n",
    "   - Database of spatial transcriptomics experiments\n",
    "   \n",
    "3. **Single Cell Portal**: https://singlecell.broadinstitute.org/\n",
    "   - Some studies include spatial data\n",
    "\n",
    "### Cancer-Specific Resources\n",
    "\n",
    "- **TISCH2**: Tumor Immune Single-cell Hub\n",
    "- **CancerSEA**: Cancer Single-cell State Atlas\n",
    "- **HTAN**: Human Tumor Atlas Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "### Completed\n",
    "- Set up spatial data download infrastructure\n",
    "- Created verification functions for data structure\n",
    "- Created spatial dataset registry\n",
    "\n",
    "### Next Steps\n",
    "1. Download remaining spatial datasets\n",
    "2. Proceed to `02_preprocessing/` for quality control\n",
    "3. Spatial data will be integrated in `05_spatial_analysis/`\n",
    "\n",
    "### Important Considerations\n",
    "- Spatial data files are large (images + counts)\n",
    "- Ensure consistent coordinate systems\n",
    "- Match spatial samples with corresponding scRNA-seq if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final status\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPATIAL DATA DOWNLOAD STATUS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "downloaded = spatial_df['downloaded'].sum()\n",
    "total = len(spatial_df)\n",
    "\n",
    "print(f\"\\nDownloaded: {downloaded}/{total} spatial datasets\")\n",
    "\n",
    "if downloaded < total:\n",
    "    print(f\"\\nPending downloads:\")\n",
    "    for _, row in spatial_df[~spatial_df['downloaded']].iterrows():\n",
    "        print(f\"  - {row['geo_id']}: {row['cancer_type']} ({row['platform']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
