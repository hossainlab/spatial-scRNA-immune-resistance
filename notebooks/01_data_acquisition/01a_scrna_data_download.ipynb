{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scRNA-seq Data Download from GEO\n",
    "\n",
    "## Overview\n",
    "This notebook downloads and organizes single-cell RNA sequencing datasets from the Gene Expression Omnibus (GEO) for the immunotherapy resistance atlas.\n",
    "\n",
    "### Datasets\n",
    "| GEO ID | Cancer Type | Treatment | Patients |\n",
    "|--------|-------------|-----------|----------|\n",
    "| GSE115978 | Melanoma | anti-PD-1 | 48 |\n",
    "| GSE123813 | BCC | anti-PD-1 | 10 |\n",
    "| GSE212966 | PDAC | TME | - |\n",
    "| GSE149614 | HCC | ICIs | - |\n",
    "| GSE197177 | PDAC | TME | - |\n",
    "| GSE206785 | Gastric | Metastasis | - |\n",
    "| GSE183904 | Gastric | T cell | - |\n",
    "| GSE130000 | Ovarian | Relapse | - |\n",
    "| GSE202642 | HCC | Adjacent | - |\n",
    "\n",
    "### Output\n",
    "- Raw count matrices organized by GEO ID\n",
    "- Metadata files with sample information\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "# Try to import GEOparse\n",
    "try:\n",
    "    import GEOparse\n",
    "    print(f\"GEOparse version: {GEOparse.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"GEOparse not installed. Install with: pip install GEOparse\")\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "DATA_RAW = PROJECT_ROOT / 'data' / 'raw' / 'scrna'\n",
    "CONFIG_PATH = PROJECT_ROOT / 'config' / 'analysis_params.yaml'\n",
    "\n",
    "print(f\"Data will be saved to: {DATA_RAW}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Get dataset list\n",
    "datasets = config['datasets']['scrna']\n",
    "\n",
    "print(f\"Datasets to download: {len(datasets)}\")\n",
    "for ds in datasets:\n",
    "    print(f\"  - {ds['id']}: {ds['cancer_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Download Functions\n",
    "\n",
    "We provide multiple methods to download GEO data:\n",
    "1. **GEOparse**: Parse GEO SOFT files and download supplementary data\n",
    "2. **Direct FTP**: Download from NCBI FTP server\n",
    "3. **SRA Tools**: For raw sequencing data (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, output_path, chunk_size=8192):\n",
    "    \"\"\"\n",
    "    Download file with progress bar.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL to download\n",
    "    output_path : Path\n",
    "        Output file path\n",
    "    chunk_size : int\n",
    "        Chunk size for streaming download\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(output_path, 'wb') as f:\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=output_path.name) as pbar:\n",
    "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                f.write(chunk)\n",
    "                pbar.update(len(chunk))\n",
    "\n",
    "\n",
    "def get_geo_supplementary_files(geo_id, output_dir):\n",
    "    \"\"\"\n",
    "    Download supplementary files from GEO using GEOparse.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    geo_id : str\n",
    "        GEO accession (e.g., 'GSE115978')\n",
    "    output_dir : Path\n",
    "        Directory to save files\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of downloaded file paths\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nDownloading {geo_id}...\")\n",
    "    \n",
    "    # Parse GEO entry\n",
    "    gse = GEOparse.get_GEO(geo=geo_id, destdir=str(output_dir), silent=True)\n",
    "    \n",
    "    downloaded_files = []\n",
    "    \n",
    "    # Get supplementary files\n",
    "    for gsm_name, gsm in gse.gsms.items():\n",
    "        for supp_file in gsm.metadata.get('supplementary_file', []):\n",
    "            if supp_file:\n",
    "                filename = supp_file.split('/')[-1]\n",
    "                filepath = output_dir / filename\n",
    "                \n",
    "                if not filepath.exists():\n",
    "                    print(f\"  Downloading: {filename}\")\n",
    "                    download_file(supp_file, filepath)\n",
    "                else:\n",
    "                    print(f\"  Already exists: {filename}\")\n",
    "                \n",
    "                downloaded_files.append(filepath)\n",
    "    \n",
    "    return downloaded_files\n",
    "\n",
    "\n",
    "def extract_archive(archive_path, output_dir):\n",
    "    \"\"\"\n",
    "    Extract tar.gz or gz files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    archive_path : Path\n",
    "        Path to archive\n",
    "    output_dir : Path\n",
    "        Extraction directory\n",
    "    \"\"\"\n",
    "    archive_path = Path(archive_path)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    if archive_path.suffix == '.gz' and '.tar' in archive_path.suffixes:\n",
    "        # tar.gz file\n",
    "        with tarfile.open(archive_path, 'r:gz') as tar:\n",
    "            tar.extractall(output_dir)\n",
    "    elif archive_path.suffix == '.gz':\n",
    "        # gzip file\n",
    "        output_file = output_dir / archive_path.stem\n",
    "        with gzip.open(archive_path, 'rb') as f_in:\n",
    "            with open(output_file, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(\"Download functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Datasets\n",
    "\n",
    "### Important Notes:\n",
    "- Some datasets may require manual download due to size or access restrictions\n",
    "- Check each GEO page for data format (10x Genomics, Smart-seq2, etc.)\n",
    "- Large datasets may take significant time to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create download tracking\n",
    "download_status = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    geo_id = dataset['id']\n",
    "    cancer_type = dataset['cancer_type']\n",
    "    \n",
    "    output_dir = DATA_RAW / geo_id\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if already downloaded\n",
    "    existing_files = list(output_dir.glob('*'))\n",
    "    \n",
    "    status = {\n",
    "        'geo_id': geo_id,\n",
    "        'cancer_type': cancer_type,\n",
    "        'output_dir': str(output_dir),\n",
    "        'status': 'exists' if existing_files else 'pending'\n",
    "    }\n",
    "    \n",
    "    download_status.append(status)\n",
    "\n",
    "# Display status\n",
    "status_df = pd.DataFrame(download_status)\n",
    "print(\"Download status:\")\n",
    "display(status_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 GSE115978 - Melanoma anti-PD-1\n",
    "\n",
    "This is a key dataset with 48 patients treated with anti-PD-1, including pre- and post-treatment samples.\n",
    "\n",
    "**Reference**: Sade-Feldman et al., Cell 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GSE115978\n",
    "geo_id = \"GSE115978\"\n",
    "output_dir = DATA_RAW / geo_id\n",
    "\n",
    "# This dataset has processed count matrices\n",
    "# Files typically include:\n",
    "# - TPM matrix\n",
    "# - Metadata with response information\n",
    "\n",
    "print(f\"Downloading {geo_id}...\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(\"\\nNote: This dataset may require manual download from GEO.\")\n",
    "print(f\"GEO URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={geo_id}\")\n",
    "\n",
    "# Uncomment to download using GEOparse:\n",
    "# files = get_geo_supplementary_files(geo_id, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Manual Download Instructions\n",
    "\n",
    "For large datasets or those with complex structures, manual download is recommended:\n",
    "\n",
    "1. Go to https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSEXXX\n",
    "2. Scroll to \"Supplementary file\" section\n",
    "3. Download the count matrix files (usually .txt.gz or .h5 format)\n",
    "4. Place in the corresponding `data/raw/scrna/GSEXXX/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Download using wget/curl commands\n",
    "# You can run these in terminal or use subprocess\n",
    "\n",
    "download_commands = {\n",
    "    'GSE115978': [\n",
    "        # Example - adjust based on actual GEO supplementary files\n",
    "        'wget -P data/raw/scrna/GSE115978/ \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE115nnn/GSE115978/suppl/GSE115978_RAW.tar\"',\n",
    "    ],\n",
    "    'GSE123813': [\n",
    "        'wget -P data/raw/scrna/GSE123813/ \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE123nnn/GSE123813/suppl/GSE123813_RAW.tar\"',\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"Manual download commands (run in terminal):\")\n",
    "print(\"=\"*60)\n",
    "for geo_id, commands in download_commands.items():\n",
    "    print(f\"\\n# {geo_id}\")\n",
    "    for cmd in commands:\n",
    "        print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Downloaded Data\n",
    "\n",
    "After downloading, we need to:\n",
    "1. Extract archives\n",
    "2. Identify file formats (10x, Smart-seq2, etc.)\n",
    "3. Convert to AnnData format for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_data_format(directory):\n",
    "    \"\"\"\n",
    "    Identify the scRNA-seq data format in a directory.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Data format: '10x_h5', '10x_mtx', 'csv', 'txt', 'h5ad', or 'unknown'\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    files = list(directory.rglob('*'))\n",
    "    \n",
    "    # Check for different formats\n",
    "    extensions = [f.suffix for f in files if f.is_file()]\n",
    "    filenames = [f.name for f in files if f.is_file()]\n",
    "    \n",
    "    if any('.h5ad' in str(f) for f in files):\n",
    "        return 'h5ad'\n",
    "    elif any('filtered_feature_bc_matrix.h5' in str(f) for f in files):\n",
    "        return '10x_h5'\n",
    "    elif any('matrix.mtx' in str(f) for f in files):\n",
    "        return '10x_mtx'\n",
    "    elif '.h5' in extensions:\n",
    "        return '10x_h5'\n",
    "    elif '.csv' in extensions or '.txt' in extensions:\n",
    "        return 'csv_txt'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "\n",
    "def load_10x_data(directory):\n",
    "    \"\"\"\n",
    "    Load 10x Genomics data from directory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : Path\n",
    "        Directory containing 10x output\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    AnnData\n",
    "        Loaded data\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    \n",
    "    # Try h5 file first\n",
    "    h5_files = list(directory.rglob('*.h5'))\n",
    "    if h5_files:\n",
    "        return sc.read_10x_h5(h5_files[0])\n",
    "    \n",
    "    # Try mtx directory\n",
    "    mtx_files = list(directory.rglob('matrix.mtx*'))\n",
    "    if mtx_files:\n",
    "        mtx_dir = mtx_files[0].parent\n",
    "        return sc.read_10x_mtx(mtx_dir)\n",
    "    \n",
    "    raise FileNotFoundError(f\"No 10x data found in {directory}\")\n",
    "\n",
    "\n",
    "print(\"Data loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check downloaded data formats\n",
    "print(\"Checking data formats in downloaded directories:\\n\")\n",
    "\n",
    "for dataset in datasets:\n",
    "    geo_id = dataset['id']\n",
    "    data_dir = DATA_RAW / geo_id\n",
    "    \n",
    "    if data_dir.exists() and any(data_dir.iterdir()):\n",
    "        format_type = identify_data_format(data_dir)\n",
    "        n_files = len(list(data_dir.rglob('*')))\n",
    "        print(f\"{geo_id}: {format_type} ({n_files} files)\")\n",
    "    else:\n",
    "        print(f\"{geo_id}: NOT DOWNLOADED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Dataset Metadata Registry\n",
    "\n",
    "We'll create a metadata file tracking all datasets and their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive metadata\n",
    "metadata_records = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    geo_id = dataset['id']\n",
    "    data_dir = DATA_RAW / geo_id\n",
    "    \n",
    "    record = {\n",
    "        'geo_id': geo_id,\n",
    "        'cancer_type': dataset['cancer_type'],\n",
    "        'treatment': dataset.get('treatment', 'N/A'),\n",
    "        'n_patients': dataset.get('n_patients', 'Unknown'),\n",
    "        'timepoints': ', '.join(dataset.get('timepoints', [])),\n",
    "        'data_path': str(data_dir),\n",
    "        'downloaded': data_dir.exists() and any(data_dir.iterdir()) if data_dir.exists() else False,\n",
    "        'format': identify_data_format(data_dir) if data_dir.exists() else 'N/A'\n",
    "    }\n",
    "    \n",
    "    metadata_records.append(record)\n",
    "\n",
    "# Create DataFrame\n",
    "metadata_df = pd.DataFrame(metadata_records)\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = DATA_RAW / 'dataset_metadata.csv'\n",
    "metadata_df.to_csv(metadata_path, index=False)\n",
    "\n",
    "print(f\"Metadata saved to: {metadata_path}\")\n",
    "display(metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Next Steps\n",
    "\n",
    "### Completed\n",
    "- Set up download infrastructure\n",
    "- Created dataset metadata registry\n",
    "- Identified data formats\n",
    "\n",
    "### Next Steps\n",
    "1. Complete manual downloads for remaining datasets\n",
    "2. Proceed to `01b_spatial_data_download.ipynb` for spatial transcriptomics data\n",
    "3. Continue to `02_preprocessing/` notebooks for quality control\n",
    "\n",
    "### Data Access Notes\n",
    "- Some datasets may require dbGaP access for controlled data\n",
    "- Check GEO page for any usage restrictions\n",
    "- Large datasets (>10GB) may take hours to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final status summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DOWNLOAD STATUS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "downloaded = metadata_df['downloaded'].sum()\n",
    "total = len(metadata_df)\n",
    "\n",
    "print(f\"\\nDownloaded: {downloaded}/{total} datasets\")\n",
    "print(f\"\\nPending downloads:\")\n",
    "for _, row in metadata_df[~metadata_df['downloaded']].iterrows():\n",
    "    print(f\"  - {row['geo_id']}: {row['cancer_type']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
